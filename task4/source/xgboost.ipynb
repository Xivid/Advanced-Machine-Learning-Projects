{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting lightbgm\n",
      "\u001b[31m  Could not find a version that satisfies the requirement lightbgm (from versions: )\u001b[0m\n",
      "\u001b[31mNo matching distribution found for lightbgm\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip install lightbgm\n",
    "#!conda install scikit-learn\n",
    "import os\n",
    "import tensorflow as tf\t\n",
    "import numpy as np\n",
    "import time\n",
    "from tf_utils import input_fn_from_dataset,input_fn_frame_from_dataset,save_tf_record,prob_positive_class_from_prediction\n",
    "from get_data import get_videos_from_folder,get_target_from_csv\n",
    "from utils import save_solution\n",
    "from keras.layers import Dense, Flatten, Dropout, ZeroPadding3D\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "from keras.layers.wrappers import TimeDistributed\n",
    "from keras.layers.convolutional import (Conv2D, MaxPooling3D, Conv3D,\n",
    "                                        MaxPooling2D)\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint, EarlyStopping, CSVLogger\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from keras import backend as K\n",
    "from keras import metrics\n",
    "from sklearn.utils.validation import check_array\n",
    "import lightgbm as lgb\n",
    "import pandas as pd\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pframe=40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_folder = os.path.join(\"../train/\")\n",
    "test_folder = os.path.join(\"../test/\")\n",
    "\n",
    "train_target = os.path.join('../train_target.csv')\n",
    "my_solution_file = os.path.join('../solution.csv')\n",
    "\n",
    "tf_record_dir = os.path.join('..','tf_records')\n",
    "os.makedirs(tf_record_dir, exist_ok=True)\n",
    "\n",
    "tf_record_train = os.path.join(tf_record_dir, 'train' + '.tfrecords')\n",
    "tf_record_test = os.path.join(tf_record_dir, 'test' + '.tfrecords')\n",
    "x_train = get_videos_from_folder(train_folder)\n",
    "y_train = get_target_from_csv(train_target)\n",
    "X = np.zeros((x_train.shape[0], pframe, 100, 100,1))\n",
    "\n",
    "for i in range(x_train.shape[0]):\n",
    "    if x_train[i].shape[0] >= pframe:\n",
    "        X[i,: pframe,:x_train[i].shape[1],:x_train[i].shape[2],0] = x_train[i][: pframe,:x_train[i].shape[1],:x_train[i].shape[2]]\n",
    "    else:\n",
    "        # repeated padding\n",
    "        frames, height, width = x_train[i].shape[0], x_train[i].shape[1], x_train[i].shape[2]\n",
    "        pos = 0\n",
    "        while pos + frames <= pframe:\n",
    "            X[i,pos:(pos+frames),:height,:width,0] = x_train[i][:frames,:height,:width]\n",
    "            pos += frames\n",
    "        if pos < pframe:\n",
    "            X[i,pos:pframe,:height,:width,0] = x_train[i][:(pframe-pos),:height,:width]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = get_target_from_csv(train_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validate( split_size=5):\n",
    "    results = []\n",
    "    kf = KFold(n_splits=split_size)\n",
    "    for train_idx, val_idx in kf.split(X, y_train):\n",
    "        train_x = X[train_idx]\n",
    "        train_y = y_train[train_idx]\n",
    "        val_x = X[val_idx]\n",
    "        val_y = y_train[val_idx]\n",
    "        His=model.fit(train_x, train_y, batch_size=32, validation_data=(val_x,val_y),verbose=1,callbacks=[tb, early_stopper, csv_logger], epochs=nb_epoch)\n",
    "        results.append(His,history)\n",
    "    return results\n",
    "results=cross_validate(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = get_videos_from_folder(test_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.zeros((x_test.shape[0],  pframe, 100, 100,1))\n",
    "for i in range(x_test.shape[0]):\n",
    "    if x_test[i].shape[0]>= pframe:\n",
    "        X_test[i,: pframe,:x_test[i].shape[1],:x_test[i].shape[2],0] = x_test[i][: pframe,:x_test[i].shape[1],:x_test[i].shape[2]]\n",
    "    else:\n",
    "        # repeated padding\n",
    "        frames, height, width = x_test[i].shape[0], x_test[i].shape[1], x_test[i].shape[2]\n",
    "        pos = 0\n",
    "        while pos + frames <= pframe:\n",
    "            X_test[i,pos:(pos+frames),:height,:width,0] = x_test[i][:frames,:height,:width]\n",
    "            pos += frames\n",
    "        if pos < pframe:\n",
    "            X_test[i,pos:pframe,:height,:width,0] = x_test[i][:(pframe-pos),:height,:width]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_cell_edges = np.linspace(0,40,4,dtype=int)\n",
    "y_cell_edges = np.linspace(0,100,9,dtype=int)\n",
    "z_cell_edges = np.linspace(0,100,9,dtype=int)\n",
    "\n",
    "        # histograms\n",
    "histogram_train = np.zeros((X.shape[0], 3,8,8, 45))\n",
    "histogram_test = np.zeros((X_test.shape[0], 3,8,8, 45))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, X.shape[0]):\n",
    "    image_3D = X[i, :, :, :,0]\n",
    "\n",
    "    for xi in range(0, x_cell_edges.size - 1):\n",
    "        for yi in range(0, y_cell_edges.size - 1):\n",
    "            for zi in range(0, z_cell_edges.size - 1):\n",
    "\n",
    "                        # image block for histogram\n",
    "                image_block = image_3D[\n",
    "                                      x_cell_edges[xi]:x_cell_edges[xi+1],\n",
    "                                      y_cell_edges[yi]:y_cell_edges[yi+1],\n",
    "                                      z_cell_edges[zi]:z_cell_edges[zi+1]]\n",
    "\n",
    "                        # histogram\n",
    "                histogram_train[i, xi, yi, zi, :], bins = \\\n",
    "                            np.histogram(image_block,\n",
    "                                         bins=np.linspace(0,\n",
    "                                                          4500,\n",
    "                                                          45 + 1))\n",
    "\n",
    "X_new = np.reshape(histogram_train, (X.shape[0], -1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, X_test.shape[0]):\n",
    "    image_3D = X_test[i, :, :, :,0]\n",
    "\n",
    "    for xi in range(0, x_cell_edges.size - 1):\n",
    "        for yi in range(0, y_cell_edges.size - 1):\n",
    "            for zi in range(0, z_cell_edges.size - 1):\n",
    "\n",
    "                        # image block for histogram\n",
    "                image_block = image_3D[\n",
    "                                      x_cell_edges[xi]:x_cell_edges[xi+1],\n",
    "                                      y_cell_edges[yi]:y_cell_edges[yi+1],\n",
    "                                      z_cell_edges[zi]:z_cell_edges[zi+1]]\n",
    "\n",
    "                        # histogram\n",
    "                histogram_test[i, xi, yi, zi, :], bins = \\\n",
    "                            np.histogram(image_block,\n",
    "                                         bins=np.linspace(0,\n",
    "                                                          4500,\n",
    "                                                          45 + 1))\n",
    "\n",
    "X_test_new = np.reshape(histogram_test, (X_test.shape[0], -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_new, y_train, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_train = lgb.Dataset(X_train, y_train)\n",
    "lgb_eval = lgb.Dataset(X_val, y_val, reference=lgb_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training...\n",
      "[1]\ttraining's binary_logloss: 0.684001\ttraining's r2: 0.715474\tvalid_0's binary_logloss: 0.693779\tvalid_0's r2: 0.539216\n",
      "Training until validation scores don't improve for 20 rounds.\n",
      "[2]\ttraining's binary_logloss: 0.6743\ttraining's r2: 0.743448\tvalid_0's binary_logloss: 0.695332\tvalid_0's r2: 0.541176\n",
      "[3]\ttraining's binary_logloss: 0.667527\ttraining's r2: 0.751638\tvalid_0's binary_logloss: 0.692202\tvalid_0's r2: 0.562745\n",
      "[4]\ttraining's binary_logloss: 0.658272\ttraining's r2: 0.797883\tvalid_0's binary_logloss: 0.687966\tvalid_0's r2: 0.592157\n",
      "[5]\ttraining's binary_logloss: 0.649823\ttraining's r2: 0.826235\tvalid_0's binary_logloss: 0.687125\tvalid_0's r2: 0.582353\n",
      "[6]\ttraining's binary_logloss: 0.63848\ttraining's r2: 0.863911\tvalid_0's binary_logloss: 0.685909\tvalid_0's r2: 0.57451\n",
      "[7]\ttraining's binary_logloss: 0.628578\ttraining's r2: 0.86807\tvalid_0's binary_logloss: 0.687486\tvalid_0's r2: 0.55098\n",
      "[8]\ttraining's binary_logloss: 0.618834\ttraining's r2: 0.87752\tvalid_0's binary_logloss: 0.686636\tvalid_0's r2: 0.584314\n",
      "[9]\ttraining's binary_logloss: 0.61171\ttraining's r2: 0.886467\tvalid_0's binary_logloss: 0.681549\tvalid_0's r2: 0.566667\n",
      "[10]\ttraining's binary_logloss: 0.601717\ttraining's r2: 0.895665\tvalid_0's binary_logloss: 0.673472\tvalid_0's r2: 0.613725\n",
      "[11]\ttraining's binary_logloss: 0.594815\ttraining's r2: 0.888357\tvalid_0's binary_logloss: 0.673337\tvalid_0's r2: 0.629412\n",
      "[12]\ttraining's binary_logloss: 0.58468\ttraining's r2: 0.892137\tvalid_0's binary_logloss: 0.669024\tvalid_0's r2: 0.645098\n",
      "[13]\ttraining's binary_logloss: 0.573082\ttraining's r2: 0.898438\tvalid_0's binary_logloss: 0.664386\tvalid_0's r2: 0.641176\n",
      "[14]\ttraining's binary_logloss: 0.563221\ttraining's r2: 0.896673\tvalid_0's binary_logloss: 0.661305\tvalid_0's r2: 0.660784\n",
      "[15]\ttraining's binary_logloss: 0.558826\ttraining's r2: 0.895665\tvalid_0's binary_logloss: 0.664373\tvalid_0's r2: 0.64902\n",
      "[16]\ttraining's binary_logloss: 0.552591\ttraining's r2: 0.900454\tvalid_0's binary_logloss: 0.663126\tvalid_0's r2: 0.645098\n",
      "[17]\ttraining's binary_logloss: 0.548097\ttraining's r2: 0.902722\tvalid_0's binary_logloss: 0.666286\tvalid_0's r2: 0.633333\n",
      "[18]\ttraining's binary_logloss: 0.543271\ttraining's r2: 0.906754\tvalid_0's binary_logloss: 0.661702\tvalid_0's r2: 0.633333\n",
      "[19]\ttraining's binary_logloss: 0.53789\ttraining's r2: 0.909778\tvalid_0's binary_logloss: 0.661368\tvalid_0's r2: 0.617647\n",
      "[20]\ttraining's binary_logloss: 0.532473\ttraining's r2: 0.91003\tvalid_0's binary_logloss: 0.662907\tvalid_0's r2: 0.633333\n",
      "[21]\ttraining's binary_logloss: 0.526684\ttraining's r2: 0.909022\tvalid_0's binary_logloss: 0.662021\tvalid_0's r2: 0.643137\n",
      "[22]\ttraining's binary_logloss: 0.521649\ttraining's r2: 0.910282\tvalid_0's binary_logloss: 0.657894\tvalid_0's r2: 0.647059\n",
      "[23]\ttraining's binary_logloss: 0.517918\ttraining's r2: 0.909022\tvalid_0's binary_logloss: 0.655414\tvalid_0's r2: 0.658824\n",
      "[24]\ttraining's binary_logloss: 0.513622\ttraining's r2: 0.908266\tvalid_0's binary_logloss: 0.653612\tvalid_0's r2: 0.670588\n",
      "[25]\ttraining's binary_logloss: 0.508184\ttraining's r2: 0.910282\tvalid_0's binary_logloss: 0.652199\tvalid_0's r2: 0.678431\n",
      "[26]\ttraining's binary_logloss: 0.502948\ttraining's r2: 0.914062\tvalid_0's binary_logloss: 0.650283\tvalid_0's r2: 0.682353\n",
      "[27]\ttraining's binary_logloss: 0.497986\ttraining's r2: 0.918095\tvalid_0's binary_logloss: 0.645987\tvalid_0's r2: 0.67451\n",
      "[28]\ttraining's binary_logloss: 0.493535\ttraining's r2: 0.920111\tvalid_0's binary_logloss: 0.645891\tvalid_0's r2: 0.694118\n",
      "[29]\ttraining's binary_logloss: 0.487218\ttraining's r2: 0.927167\tvalid_0's binary_logloss: 0.644608\tvalid_0's r2: 0.694118\n",
      "[30]\ttraining's binary_logloss: 0.482929\ttraining's r2: 0.929435\tvalid_0's binary_logloss: 0.644717\tvalid_0's r2: 0.686275\n",
      "[31]\ttraining's binary_logloss: 0.479969\ttraining's r2: 0.928175\tvalid_0's binary_logloss: 0.646388\tvalid_0's r2: 0.686275\n",
      "[32]\ttraining's binary_logloss: 0.475478\ttraining's r2: 0.926663\tvalid_0's binary_logloss: 0.648663\tvalid_0's r2: 0.686275\n",
      "[33]\ttraining's binary_logloss: 0.471886\ttraining's r2: 0.927419\tvalid_0's binary_logloss: 0.647854\tvalid_0's r2: 0.698039\n",
      "[34]\ttraining's binary_logloss: 0.468661\ttraining's r2: 0.929688\tvalid_0's binary_logloss: 0.647366\tvalid_0's r2: 0.694118\n",
      "[35]\ttraining's binary_logloss: 0.466242\ttraining's r2: 0.9312\tvalid_0's binary_logloss: 0.644462\tvalid_0's r2: 0.686275\n",
      "[36]\ttraining's binary_logloss: 0.46112\ttraining's r2: 0.931956\tvalid_0's binary_logloss: 0.641526\tvalid_0's r2: 0.694118\n",
      "[37]\ttraining's binary_logloss: 0.45644\ttraining's r2: 0.934224\tvalid_0's binary_logloss: 0.638342\tvalid_0's r2: 0.694118\n",
      "[38]\ttraining's binary_logloss: 0.451213\ttraining's r2: 0.935232\tvalid_0's binary_logloss: 0.638752\tvalid_0's r2: 0.690196\n",
      "[39]\ttraining's binary_logloss: 0.447435\ttraining's r2: 0.936996\tvalid_0's binary_logloss: 0.636274\tvalid_0's r2: 0.698039\n",
      "[40]\ttraining's binary_logloss: 0.442988\ttraining's r2: 0.937752\tvalid_0's binary_logloss: 0.633904\tvalid_0's r2: 0.690196\n",
      "[41]\ttraining's binary_logloss: 0.438175\ttraining's r2: 0.940776\tvalid_0's binary_logloss: 0.634232\tvalid_0's r2: 0.701961\n",
      "[42]\ttraining's binary_logloss: 0.433409\ttraining's r2: 0.940524\tvalid_0's binary_logloss: 0.637168\tvalid_0's r2: 0.698039\n",
      "[43]\ttraining's binary_logloss: 0.430102\ttraining's r2: 0.941028\tvalid_0's binary_logloss: 0.633194\tvalid_0's r2: 0.701961\n",
      "[44]\ttraining's binary_logloss: 0.425838\ttraining's r2: 0.944556\tvalid_0's binary_logloss: 0.637115\tvalid_0's r2: 0.686275\n",
      "[45]\ttraining's binary_logloss: 0.421448\ttraining's r2: 0.945817\tvalid_0's binary_logloss: 0.643564\tvalid_0's r2: 0.678431\n",
      "[46]\ttraining's binary_logloss: 0.418585\ttraining's r2: 0.947581\tvalid_0's binary_logloss: 0.640139\tvalid_0's r2: 0.686275\n",
      "[47]\ttraining's binary_logloss: 0.41532\ttraining's r2: 0.949849\tvalid_0's binary_logloss: 0.64012\tvalid_0's r2: 0.686275\n",
      "[48]\ttraining's binary_logloss: 0.41191\ttraining's r2: 0.952621\tvalid_0's binary_logloss: 0.64408\tvalid_0's r2: 0.678431\n",
      "[49]\ttraining's binary_logloss: 0.408671\ttraining's r2: 0.953377\tvalid_0's binary_logloss: 0.645189\tvalid_0's r2: 0.666667\n",
      "[50]\ttraining's binary_logloss: 0.405902\ttraining's r2: 0.954889\tvalid_0's binary_logloss: 0.649197\tvalid_0's r2: 0.658824\n",
      "[51]\ttraining's binary_logloss: 0.402927\ttraining's r2: 0.957409\tvalid_0's binary_logloss: 0.646227\tvalid_0's r2: 0.678431\n",
      "[52]\ttraining's binary_logloss: 0.400324\ttraining's r2: 0.960181\tvalid_0's binary_logloss: 0.643667\tvalid_0's r2: 0.682353\n",
      "[53]\ttraining's binary_logloss: 0.397949\ttraining's r2: 0.963458\tvalid_0's binary_logloss: 0.644373\tvalid_0's r2: 0.686275\n",
      "[54]\ttraining's binary_logloss: 0.396278\ttraining's r2: 0.964214\tvalid_0's binary_logloss: 0.645751\tvalid_0's r2: 0.682353\n",
      "[55]\ttraining's binary_logloss: 0.393467\ttraining's r2: 0.965726\tvalid_0's binary_logloss: 0.647719\tvalid_0's r2: 0.682353\n",
      "[56]\ttraining's binary_logloss: 0.389679\ttraining's r2: 0.965474\tvalid_0's binary_logloss: 0.648651\tvalid_0's r2: 0.690196\n",
      "[57]\ttraining's binary_logloss: 0.387202\ttraining's r2: 0.965222\tvalid_0's binary_logloss: 0.647467\tvalid_0's r2: 0.694118\n",
      "[58]\ttraining's binary_logloss: 0.384506\ttraining's r2: 0.96749\tvalid_0's binary_logloss: 0.650385\tvalid_0's r2: 0.678431\n",
      "[59]\ttraining's binary_logloss: 0.382284\ttraining's r2: 0.968246\tvalid_0's binary_logloss: 0.653377\tvalid_0's r2: 0.678431\n",
      "[60]\ttraining's binary_logloss: 0.379327\ttraining's r2: 0.967238\tvalid_0's binary_logloss: 0.654696\tvalid_0's r2: 0.67451\n",
      "[61]\ttraining's binary_logloss: 0.375749\ttraining's r2: 0.967994\tvalid_0's binary_logloss: 0.655743\tvalid_0's r2: 0.678431\n",
      "Early stopping, best iteration is:\n",
      "[41]\ttraining's binary_logloss: 0.438175\ttraining's r2: 0.940776\tvalid_0's binary_logloss: 0.634232\tvalid_0's r2: 0.701961\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    'task': 'train',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'binary',\n",
    "    'num_leaves': 31,\n",
    "    'learning_rate': 0.05,\n",
    "    'feature_fraction': 0.5,\n",
    "    'bagging_fraction': 0.8,\n",
    "    'bagging_freq': 5,\n",
    "    'verbose': 0\n",
    "}\n",
    "\n",
    "def custom_r2(preds, train_data):\n",
    "    labels = train_data.get_label()\n",
    "    return 'r2', roc_auc_score(labels, preds), True\n",
    "\n",
    "print('Start training...')\n",
    "# train\n",
    "gbm = lgb.train(params,\n",
    "                lgb_train,\n",
    "                num_boost_round=500,\n",
    "                feval=custom_r2,\n",
    "                valid_sets={lgb_train, lgb_eval},\n",
    "                early_stopping_rounds=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = gbm.predict(X_test_new , num_iteration=gbm.best_iteration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.18252207, 0.18251272, 0.67538375, 0.71109725, 0.46787806,\n",
       "       0.31379273, 0.53665773, 0.81222736, 0.58728616, 0.44650795,\n",
       "       0.50558975, 0.36421496, 0.3337267 , 0.20201454, 0.47373049,\n",
       "       0.7770669 , 0.2626228 , 0.75409881, 0.48126645, 0.40506914,\n",
       "       0.37401944, 0.80731974, 0.38513308, 0.28721722, 0.53106075,\n",
       "       0.69378906, 0.37366828, 0.78667163, 0.5895963 , 0.17025691,\n",
       "       0.49923208, 0.54503384, 0.22028171, 0.32793726, 0.54588198,\n",
       "       0.60984379, 0.32898669, 0.3872737 , 0.63271649, 0.45602464,\n",
       "       0.35331358, 0.19771535, 0.44437753, 0.83911529, 0.35253823,\n",
       "       0.69483722, 0.26422159, 0.27896455, 0.81821767, 0.44600597,\n",
       "       0.6736207 , 0.46303972, 0.47458599, 0.27320103, 0.60779256,\n",
       "       0.22101977, 0.44619288, 0.77669503, 0.66139745, 0.34131124,\n",
       "       0.16926377, 0.29520012, 0.68164659, 0.4088777 , 0.76720655,\n",
       "       0.50909171, 0.56601598, 0.48724602, 0.40484814])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"submission.csv\", \"w\")\n",
    "f.write(\"id,y\\n\")\n",
    "for i,x in enumerate(y_pred):\n",
    "    f.write(\"{},{}\\n\".format(i,x))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
