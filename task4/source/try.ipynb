{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-video in /anaconda3/lib/python3.6/site-packages (1.1.11)\r\n",
      "Requirement already satisfied: numpy in /anaconda3/lib/python3.6/site-packages (from scikit-video) (1.15.4)\r\n",
      "Requirement already satisfied: scipy in /anaconda3/lib/python3.6/site-packages (from scikit-video) (1.1.0)\r\n",
      "Requirement already satisfied: pillow in /anaconda3/lib/python3.6/site-packages (from scikit-video) (5.3.0)\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "! pip install scikit-video\n",
    "import os\n",
    "import tensorflow as tf\t\n",
    "import numpy as np\n",
    "import time\n",
    "from tf_utils import input_fn_from_dataset,input_fn_frame_from_dataset,save_tf_record,prob_positive_class_from_prediction\n",
    "from get_data import get_videos_from_folder,get_target_from_csv\n",
    "from utils import save_solution\n",
    "from keras.layers import Dense, Flatten, Dropout, ZeroPadding3D\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "from keras.layers.wrappers import TimeDistributed\n",
    "from keras.layers.convolutional import (Conv2D, MaxPooling3D, Conv3D,\n",
    "                                        MaxPooling2D)\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint, EarlyStopping, CSVLogger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pframe=40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_folder = os.path.join(\"../train/\")\n",
    "test_folder = os.path.join(\"../test/\")\n",
    "\n",
    "train_target = os.path.join('../train_target.csv')\n",
    "my_solution_file = os.path.join('../solution.csv')\n",
    "\n",
    "tf_record_dir = os.path.join('..','tf_records')\n",
    "os.makedirs(tf_record_dir, exist_ok=True)\n",
    "\n",
    "tf_record_train = os.path.join(tf_record_dir, 'train' + '.tfrecords')\n",
    "tf_record_test = os.path.join(tf_record_dir, 'test' + '.tfrecords')\n",
    "x_train = get_videos_from_folder(train_folder)\n",
    "y_train = get_target_from_csv(train_target)\n",
    "X = np.zeros((x_train.shape[0], pframe, 100, 100,1))\n",
    "for i in range(x_train.shape[0]):\n",
    "    if x_train[i].shape[0]>= pframe:\n",
    "        X[i,: pframe,:x_train[i].shape[1],:x_train[i].shape[2],0] = x_train[i][: pframe,:x_train[i].shape[1],:x_train[i].shape[2]]\n",
    "    else:\n",
    "         X[i,:x_train[i].shape[0],:x_train[i].shape[1],:x_train[i].shape[2],0] = x_train[i][:x_train[i].shape[0],:x_train[i].shape[1],:x_train[i].shape[2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X = np.zeros(( 158,212, 100, 100,1))\n",
    "#for i in range(158):\n",
    "    #X[i,:x_train[i].shape[0],:x_train[i].shape[1],:x_train[i].shape[2],0] = x_train[i]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "158/158 [==============================] - 73s 462ms/step - loss: 0.7543 - acc: 0.3924\n",
      "Epoch 2/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/keras/callbacks.py:569: RuntimeWarning: Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc\n",
      "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "158/158 [==============================] - 71s 447ms/step - loss: 0.7014 - acc: 0.5316\n",
      "Epoch 3/50\n",
      "158/158 [==============================] - 72s 457ms/step - loss: 0.7036 - acc: 0.5190\n",
      "Epoch 4/50\n",
      "158/158 [==============================] - 72s 454ms/step - loss: 0.6910 - acc: 0.5633\n",
      "Epoch 5/50\n",
      "158/158 [==============================] - 70s 442ms/step - loss: 0.6820 - acc: 0.5886\n",
      "Epoch 6/50\n",
      "158/158 [==============================] - 73s 459ms/step - loss: 0.6538 - acc: 0.6456\n",
      "Epoch 7/50\n",
      "158/158 [==============================] - 76s 479ms/step - loss: 0.7040 - acc: 0.5759\n",
      "Epoch 8/50\n",
      "158/158 [==============================] - 73s 460ms/step - loss: 0.6422 - acc: 0.6392\n",
      "Epoch 9/50\n",
      "158/158 [==============================] - 72s 455ms/step - loss: 0.6886 - acc: 0.5949\n",
      "Epoch 10/50\n",
      "158/158 [==============================] - 73s 463ms/step - loss: 0.6701 - acc: 0.6013\n",
      "Epoch 11/50\n",
      "158/158 [==============================] - 71s 448ms/step - loss: 0.6489 - acc: 0.6519\n",
      "Epoch 12/50\n",
      "158/158 [==============================] - 69s 439ms/step - loss: 0.6511 - acc: 0.6076\n",
      "Epoch 13/50\n",
      "158/158 [==============================] - 69s 438ms/step - loss: 0.6701 - acc: 0.5886\n",
      "Epoch 14/50\n",
      "158/158 [==============================] - 70s 445ms/step - loss: 0.6471 - acc: 0.6772\n",
      "Epoch 15/50\n",
      "158/158 [==============================] - 71s 450ms/step - loss: 0.6149 - acc: 0.6899\n",
      "Epoch 16/50\n",
      "158/158 [==============================] - 1359s 9s/step - loss: 0.6641 - acc: 0.5949\n",
      "Epoch 17/50\n",
      "158/158 [==============================] - 72s 454ms/step - loss: 0.6568 - acc: 0.6139\n",
      "Epoch 18/50\n",
      "158/158 [==============================] - 77s 486ms/step - loss: 0.6597 - acc: 0.6329\n",
      "Epoch 19/50\n",
      "158/158 [==============================] - 71s 451ms/step - loss: 0.6259 - acc: 0.6835\n",
      "Epoch 20/50\n",
      "158/158 [==============================] - 73s 465ms/step - loss: 0.6201 - acc: 0.7025\n",
      "Epoch 21/50\n",
      "158/158 [==============================] - 73s 463ms/step - loss: 0.6357 - acc: 0.7215\n",
      "Epoch 22/50\n",
      "158/158 [==============================] - 71s 448ms/step - loss: 0.6148 - acc: 0.7152\n",
      "Epoch 23/50\n",
      "158/158 [==============================] - 71s 448ms/step - loss: 0.6025 - acc: 0.7342\n",
      "Epoch 24/50\n",
      "158/158 [==============================] - 71s 452ms/step - loss: 0.6134 - acc: 0.6835\n",
      "Epoch 25/50\n",
      "158/158 [==============================] - 76s 480ms/step - loss: 0.6141 - acc: 0.6899\n",
      "Epoch 26/50\n",
      "158/158 [==============================] - 72s 456ms/step - loss: 0.5742 - acc: 0.7658\n",
      "Epoch 27/50\n",
      "158/158 [==============================] - 72s 456ms/step - loss: 0.5761 - acc: 0.7405\n",
      "Epoch 28/50\n",
      "158/158 [==============================] - 71s 451ms/step - loss: 0.5579 - acc: 0.7975\n",
      "Epoch 29/50\n",
      "158/158 [==============================] - 70s 441ms/step - loss: 0.5734 - acc: 0.7152\n",
      "Epoch 30/50\n",
      "158/158 [==============================] - 72s 455ms/step - loss: 0.5666 - acc: 0.7595\n",
      "Epoch 31/50\n",
      "158/158 [==============================] - 69s 434ms/step - loss: 0.5476 - acc: 0.7911\n",
      "Epoch 32/50\n",
      "158/158 [==============================] - 70s 443ms/step - loss: 0.5740 - acc: 0.7342\n",
      "Epoch 33/50\n",
      "158/158 [==============================] - 69s 439ms/step - loss: 0.5437 - acc: 0.7722\n",
      "Epoch 34/50\n",
      "158/158 [==============================] - 72s 457ms/step - loss: 0.5345 - acc: 0.8038\n",
      "Epoch 35/50\n",
      "158/158 [==============================] - 70s 445ms/step - loss: 0.5237 - acc: 0.7848\n",
      "Epoch 36/50\n",
      "158/158 [==============================] - 69s 440ms/step - loss: 0.5094 - acc: 0.8101\n",
      "Epoch 37/50\n",
      "158/158 [==============================] - 73s 464ms/step - loss: 0.5087 - acc: 0.8165\n",
      "Epoch 38/50\n",
      "158/158 [==============================] - 70s 442ms/step - loss: 0.4924 - acc: 0.8481\n",
      "Epoch 39/50\n",
      "158/158 [==============================] - 71s 449ms/step - loss: 0.4576 - acc: 0.8797\n",
      "Epoch 40/50\n",
      "158/158 [==============================] - 72s 453ms/step - loss: 0.4905 - acc: 0.8228\n",
      "Epoch 41/50\n",
      "158/158 [==============================] - 72s 454ms/step - loss: 0.4819 - acc: 0.8165\n",
      "Epoch 42/50\n",
      "158/158 [==============================] - 72s 454ms/step - loss: 0.4935 - acc: 0.8165\n",
      "Epoch 43/50\n",
      "158/158 [==============================] - 71s 450ms/step - loss: 0.4510 - acc: 0.8418\n",
      "Epoch 44/50\n",
      "158/158 [==============================] - 71s 451ms/step - loss: 0.4295 - acc: 0.8418\n",
      "Epoch 45/50\n",
      "158/158 [==============================] - 70s 446ms/step - loss: 0.4134 - acc: 0.8987\n",
      "Epoch 46/50\n",
      "158/158 [==============================] - 70s 440ms/step - loss: 0.3945 - acc: 0.9114\n",
      "Epoch 47/50\n",
      "158/158 [==============================] - 71s 447ms/step - loss: 0.3883 - acc: 0.9177\n",
      "Epoch 48/50\n",
      "158/158 [==============================] - 70s 444ms/step - loss: 0.3842 - acc: 0.9177\n",
      "Epoch 49/50\n",
      "158/158 [==============================] - 71s 448ms/step - loss: 0.3744 - acc: 0.8861\n",
      "Epoch 50/50\n",
      "158/158 [==============================] - 70s 445ms/step - loss: 0.3711 - acc: 0.9051\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c52ae1e80>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batchsize_video = 1\n",
    "nb_epoch=50\n",
    "checkpointer = ModelCheckpoint( filepath=os.path.join('data', 'checkpoints', 'lcrn' + '-' + \\\n",
    "            '.{epoch:03d}-{val_loss:.3f}.hdf5'),\n",
    "        verbose=1,\n",
    "        save_best_only=True)\n",
    "\n",
    "    \n",
    "tb = TensorBoard(log_dir=os.path.join('data', 'logs', 'lcrn'))\n",
    "early_stopper = EarlyStopping(patience=5)\n",
    "timestamp = time.time()\n",
    "csv_logger = CSVLogger(os.path.join('data', 'logs', 'lcrn' + '-' + 'training-' + str(timestamp) + '.log'))\n",
    "model = Sequential()\n",
    "model.add(TimeDistributed(Conv2D(32, (7, 7), strides=(2, 2),activation='relu',padding='same'), input_shape=( pframe, 100, 100,1)))\n",
    "model.add(TimeDistributed(Conv2D(32, (3,3),\n",
    "kernel_initializer=\"he_normal\", activation='relu')))\n",
    "model.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\n",
    "model.add(TimeDistributed(Conv2D(64, (3,3),padding='same', activation='relu')))\n",
    "model.add(TimeDistributed(Conv2D(64, (3,3),padding='same', activation='relu')))\n",
    "model.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\n",
    "model.add(TimeDistributed(Conv2D(128, (3,3), padding='same', activation='relu')))\n",
    "model.add(TimeDistributed(Conv2D(128, (3,3),padding='same', activation='relu')))\n",
    "model.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\n",
    "model.add(TimeDistributed(Conv2D(256, (3,3),padding='same', activation='relu')))\n",
    "model.add(TimeDistributed(Conv2D(256, (3,3),padding='same', activation='relu')))\n",
    "model.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\n",
    "model.add(TimeDistributed(Conv2D(512, (3,3),padding='same', activation='relu')))\n",
    "model.add(TimeDistributed(Conv2D(512, (3,3),padding='same', activation='relu')))\n",
    "model.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\n",
    "model.add(TimeDistributed(Flatten()))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(256, return_sequences=False, dropout=0.5))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "metrics = ['accuracy']\n",
    "optimizer = Adam(lr=1e-5, decay=1e-6)\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=optimizer,\n",
    "                       metrics=metrics)\n",
    "model.fit(X, y_train, batch_size=32,  verbose=1,callbacks=[tb, early_stopper, csv_logger], epochs=nb_epoch)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = get_videos_from_folder(test_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.zeros((x_test.shape[0],  pframe, 100, 100,1))\n",
    "for i in range(x_test.shape[0]):\n",
    "    if x_test[i].shape[0]>= pframe:\n",
    "        X[i,: pframe,:x_test[i].shape[1],:x_test[i].shape[2],0] = x_test[i][: pframe,:x_test[i].shape[1],:x_test[i].shape[2]]\n",
    "    else:\n",
    "         X[i,:x_test[i].shape[0],:x_test[i].shape[1],:x_test[i].shape[2],0] = x_test[i][:x_test[i].shape[0],:x_test[i].shape[1],:x_test[i].shape[2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /anaconda3/lib/python3.6/site-packages (0.23.4)\r\n",
      "Requirement already satisfied: numpy>=1.9.0 in /anaconda3/lib/python3.6/site-packages (from pandas) (1.15.4)\r\n",
      "Requirement already satisfied: python-dateutil>=2.5.0 in /anaconda3/lib/python3.6/site-packages (from pandas) (2.7.5)\r\n",
      "Requirement already satisfied: pytz>=2011k in /anaconda3/lib/python3.6/site-packages (from pandas) (2018.7)\r\n",
      "Requirement already satisfied: six>=1.5 in /anaconda3/lib/python3.6/site-packages (from python-dateutil>=2.5.0->pandas) (1.11.0)\r\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(69, 2)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "! pip install pandas\n",
    "train_predictions = model.predict(X_test) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_solution = np.array([p[1] for p in train_predictions])\n",
    "save_solution(my_solution_file,dummy_solution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
